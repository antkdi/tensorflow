{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 계층 퍼셉트론 (MLP)\n",
    "### MLP 네트워크에 대한 일반적인 학습 알고리즘은  '역전파 알고리즘' 을 사용한다.\n",
    "##### 시스템의 결과값과 기대값을 비교한다. 계산된 차이 ( 즉, 에러)에 기초에 이 알고리즘은 신경망의 시냅스에 해당하는 가중치를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch 0001 cost= 2.116159168\n",
      "Epoch 0002 cost= 0.597048687\n",
      "Epoch 0003 cost= 0.398541482\n",
      "Epoch 0004 cost= 0.292631849\n",
      "Epoch 0005 cost= 0.223589640\n",
      "Epoch 0006 cost= 0.173506536\n",
      "Epoch 0007 cost= 0.136102995\n",
      "Epoch 0008 cost= 0.106170934\n",
      "Epoch 0009 cost= 0.084325237\n",
      "Epoch 0010 cost= 0.066066858\n",
      "Epoch 0011 cost= 0.052297312\n",
      "Epoch 0012 cost= 0.040624121\n",
      "Epoch 0013 cost= 0.031596599\n",
      "Epoch 0014 cost= 0.024813710\n",
      "Epoch 0015 cost= 0.019010525\n",
      "Epoch 0016 cost= 0.014793412\n",
      "Epoch 0017 cost= 0.011264293\n",
      "Epoch 0018 cost= 0.008618943\n",
      "Epoch 0019 cost= 0.006610691\n",
      "Epoch 0020 cost= 0.005329992\n",
      "Traning phase finished\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n400AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e47dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../mnist\", one_hot=True)\n",
    "\n",
    "## 신경망에 대한 학습률 \n",
    "learning_rate = 0.001\n",
    "\n",
    "## 반복 횟수\n",
    "training_epochs = 20\n",
    "\n",
    "## 배치 한번에 분류할 이미지 수\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "## 첫번째 계층의 뉴런 수\n",
    "n_hidden_1 = 256\n",
    "\n",
    "## 두번째 계층의 뉴런 수\n",
    "n_hidden_2 = 256\n",
    "\n",
    "\n",
    "## 입력값의 크기\n",
    "n_input = 784  ## 28*28\n",
    "\n",
    "## 출력 클래스의 크기\n",
    "n_classes = 10\n",
    "\n",
    "## 입력 및출력의 크기를 완벽히 정의했고, 은닉 계층의 개수와 각 계층에서의 뉴런 개수를 정하는 방법에 대한 엄격한 기준은 없다.\n",
    "\n",
    "\n",
    "### 모델생성\n",
    "\n",
    "# 입력 텐서\n",
    "x = tf.placeholder(\"float\",[None,n_input])\n",
    "\n",
    "## 출력 텐서\n",
    "y = tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "# 각 계층의 노드 수\n",
    "h = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "\n",
    "# 계층 1에대한 편향\n",
    "bias_layer_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "\n",
    "## 레이어 1은 내적곱 + 편향 에 대한 결과를 전달\n",
    "layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x,h),bias_layer_1))\n",
    "\n",
    "## 결과값을 활성화 함수를 통해 다음 계층의 뉴런으로 전달한다\n",
    "## 은닉계층에 속한 뉴런의 활성화 함수는 선형이 될수 없다!?\n",
    "## 두번째 중간 계층 256 * 256 \n",
    "w = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "\n",
    "## 두번째 계층의 편향 텐서\n",
    "bias_layer_2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "\n",
    "## 두번째 계층의 뉴런은 계층1의 뉴런으로부터 입력값을 전달 받고 가중치 연결과 결합 후 계층2편향치를 더한다\n",
    "layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,w),bias_layer_2))\n",
    "\n",
    "## 결과 값은 다음 계층인 출력 계층으로 전달된다.\n",
    "output = tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "bias_output = tf.Variable(tf.random_normal([n_classes]))\n",
    "output_layer = tf.matmul(layer_2, output) + bias_output\n",
    "\n",
    "## 출력계층은 두번째 계층으로 부터 256 개의 입력 신호를 받게 되는데 이 값은 각 숫자에 대한 클래스에 속할 확률로 변환된다\n",
    "## 로지스틱 회귀를 위해 비용함수를 정의 한다.\n",
    "## tf.nn.softmax_cross_entropy_with_logits 함수는 소프트 맥스 계층에 대한 비용을 계산 - 로짓은 모델의 출력값으로 정규화 되지않은 로그 확률\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer,y))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer,labels=y))\n",
    "\n",
    "## 비용함수를 최소화할 옵티마이저는 다음과 같다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "##세션 실행\n",
    "\n",
    "## 그래프에 사용할 설정을 정의\n",
    "avg_set = []\n",
    "epoch_set =[]\n",
    "\n",
    "#변수 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    ## 학습 반복 횟수\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        ## 배치에 대해  total_batch 만큼 반복\n",
    "        for i in range(total_batch):\n",
    "            ## batch_size 만큼 학습 데이터를 가져옴 ( 100개 )\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            ## 학습수행 옵티마이저와 100개 학습 데이터를 인자로 \n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y:batch_ys})\n",
    "            ## 학습된 내용에 대한 비용 값을 토탈로 나눠서 평균 코스트 계산 \n",
    "            avg_cost += sess.run(cost,feed_dict={x:batch_xs, y:batch_ys})/total_batch\n",
    "            \n",
    "        if(epoch % display_step) == 0:\n",
    "            print(\"Epoch\",'%04d' % (epoch +1),\"cost=\",\"{:.9f}\".format(avg_cost))\n",
    "        avg_set.append(avg_cost)\n",
    "        epoch_set.append(epoch+1)\n",
    "    print(\"Traning phase finished\")\n",
    "    \n",
    "    ## 에폭 셋, 평균셋에 대한 시각화\n",
    "    plt.plot(epoch_set, avg_set,'o',label='MLP Traning phase')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    ## 모델평가 arg_max를 씀 ( 가장 높은값의 index를 반환 ) \n",
    "    ## output_layer의 classes는 10개이고 10개에 대한 확률에 대해 가장 높은값을 리턴하고 \n",
    "    correct_prediction = tf.equal(tf.argmax(output_layer,1),tf.argmax(y,1))\n",
    "    \n",
    "    ## 정확도 평가\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    print(\"Model Accuracy:\", accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
